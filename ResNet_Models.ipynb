{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvH1sfwNNy8J"
   },
   "outputs": [],
   "source": [
    "# Bonus\n",
    "# Implementing ResNet-34\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Loading labels using file proived on website\n",
    "labels = sio.loadmat('imagelabels.mat')['labels'][0]\n",
    "all_image_ids = [f'image_{i+1:05d}.jpg' for i in range(len(labels))]\n",
    "all_labels = [labels[i] - 1 for i in range(len(labels))]\n",
    "\n",
    "# Splitting into training, validation, and test sets (80-10-10)\n",
    "train_id, temp_id, train_labels, temp_labels = train_test_split(\n",
    "    all_image_ids, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
    ")\n",
    "val_ids, test_ids, val_labels, test_labels = train_test_split(\n",
    "    temp_id, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Defining custom Dataset class\n",
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, image_ids, labels, img_dir, transform=None):\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.image_ids[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Paths to my drive folder\n",
    "img_dir = '/content/drive/MyDrive/jpg'\n",
    "\n",
    "# Creating datasets using dataset class defined above\n",
    "train_dataset = FlowerDataset(train_id, train_labels, img_dir, transform=transform)\n",
    "val_dataset = FlowerDataset(val_ids, val_labels, img_dir, transform=transform)\n",
    "test_dataset = FlowerDataset(test_ids, test_labels, img_dir, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# `train_loader`, `val_loader`, and `test_loader` are ready for training, validation, and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeMbQ6VWNy5_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# data augmentation for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-EAYXV0Ny3n"
   },
   "outputs": [],
   "source": [
    "# Defining ResNet-34 architecture\n",
    "class SimpleBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(SimpleBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=102):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512 * block.expansion, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        layers = [block(self.in_planes, planes, stride)]\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiating the model, optimizer and scheduler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet(SimpleBlock, [3, 4, 6, 3]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DekwyLmMNy1I",
    "outputId": "9fe4ac4f-ca33-445a-9c76-f30c08dc908e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 4.2524, Val Loss: 3.6510, Train Acc: 6.46%, Val Acc: 10.13%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Train Loss: 3.6453, Val Loss: 3.3695, Train Acc: 11.20%, Val Acc: 14.41%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Train Loss: 3.3869, Val Loss: 3.2767, Train Acc: 14.41%, Val Acc: 15.75%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Train Loss: 3.1928, Val Loss: 3.1472, Train Acc: 17.55%, Val Acc: 22.34%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Train Loss: 2.9984, Val Loss: 2.8333, Train Acc: 22.07%, Val Acc: 25.64%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Train Loss: 2.7824, Val Loss: 2.4565, Train Acc: 26.10%, Val Acc: 33.21%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Train Loss: 2.5984, Val Loss: 2.5131, Train Acc: 30.30%, Val Acc: 35.78%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Train Loss: 2.3910, Val Loss: 2.1708, Train Acc: 34.73%, Val Acc: 41.03%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Train Loss: 2.2141, Val Loss: 1.9043, Train Acc: 39.18%, Val Acc: 48.47%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Train Loss: 2.0522, Val Loss: 1.8800, Train Acc: 42.63%, Val Acc: 48.47%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Train Loss: 1.9133, Val Loss: 1.6981, Train Acc: 46.37%, Val Acc: 53.97%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Train Loss: 1.7922, Val Loss: 1.7913, Train Acc: 49.96%, Val Acc: 50.43%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Train Loss: 1.6551, Val Loss: 1.7576, Train Acc: 53.06%, Val Acc: 52.75%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Train Loss: 1.5420, Val Loss: 1.6231, Train Acc: 56.19%, Val Acc: 57.14%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Train Loss: 1.3983, Val Loss: 1.5030, Train Acc: 59.33%, Val Acc: 59.95%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Train Loss: 1.2809, Val Loss: 1.4760, Train Acc: 62.71%, Val Acc: 59.46%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Train Loss: 1.1429, Val Loss: 1.4153, Train Acc: 66.07%, Val Acc: 61.78%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Train Loss: 1.0477, Val Loss: 1.3949, Train Acc: 68.81%, Val Acc: 62.03%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Train Loss: 0.9162, Val Loss: 1.3398, Train Acc: 72.55%, Val Acc: 62.64%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Train Loss: 0.8105, Val Loss: 1.3511, Train Acc: 75.61%, Val Acc: 65.20%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Train Loss: 0.7074, Val Loss: 1.3601, Train Acc: 78.84%, Val Acc: 65.93%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Train Loss: 0.6181, Val Loss: 1.4225, Train Acc: 80.81%, Val Acc: 63.98%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Train Loss: 0.4791, Val Loss: 1.4332, Train Acc: 85.21%, Val Acc: 65.32%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Train Loss: 0.4338, Val Loss: 1.3874, Train Acc: 86.17%, Val Acc: 66.91%, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Train Loss: 0.3858, Val Loss: 1.5331, Train Acc: 88.11%, Val Acc: 65.08%, LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Train Loss: 0.1878, Val Loss: 1.2034, Train Acc: 94.38%, Val Acc: 71.79%, LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Train Loss: 0.1011, Val Loss: 1.2615, Train Acc: 97.50%, Val Acc: 72.04%, LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Train Loss: 0.0833, Val Loss: 1.1913, Train Acc: 98.09%, Val Acc: 72.16%, LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Train Loss: 0.0817, Val Loss: 1.2188, Train Acc: 98.02%, Val Acc: 73.26%, LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Train Loss: 0.0637, Val Loss: 1.2793, Train Acc: 98.40%, Val Acc: 73.26%, LR: 0.000500\n"
     ]
    }
   ],
   "source": [
    "# Traininging function with accuracy and loss tracking\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=30):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, \"\n",
    "              f\"Train Acc: {train_accuracy * 100:.2f}%, Val Acc: {val_accuracy * 100:.2f}%, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# training\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_and_validate(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "### PyTorch\n",
    "- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "- [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
    "- [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) \n",
    "- [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)\n",
    "- [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
    "- [torch.optim](https://pytorch.org/docs/stable/optim.html)\n",
    "- [ReduceLROnPlateau](https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau)\n",
    "\n",
    "### ResNet Architecture\n",
    "- [ResNet Paper (arXiv)](https://arxiv.org/abs/1512.03385)\n",
    "- [torchvision.models.resnet](https://pytorch.org/vision/stable/models.html#id2)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
